import streamlit as st
from transformers import MT5ForConditionalGeneration, MT5Tokenizer, pipeline
import PyPDF2

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
MODEL_NAME = "google/mt5-small"
@st.cache_resource
def load_model():
    tokenizer = MT5Tokenizer.from_pretrained(MODEL_NAME)
    model = MT5ForConditionalGeneration.from_pretrained(MODEL_NAME)
    generator = pipeline("text2text-generation", model=model, tokenizer=tokenizer)
    return generator

generator = load_model()

# Ø¯Ø§Ù„Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† PDF
def extract_text_from_pdf(file) -> str:
    pdf_reader = PyPDF2.PdfReader(file)
    text = ""
    for page in pdf_reader.pages:
        if page.extract_text():
            text += page.extract_text() + "\n"
    return text.strip()

# Ø¯Ø§Ù„Ø© Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
def ask_model(prompt: str, max_new_tokens=500):
    outputs = generator(
        prompt,
        max_new_tokens=max_new_tokens,
        do_sample=True,
        temperature=0.7
    )
    return outputs[0]["generated_text"]

# ÙˆØ§Ø¬Ù‡Ø© Streamlit
st.title("ğŸ“„ Paper AI Assistant (Arabic)")
st.write("Ø§Ø±ÙØ¹ ÙˆØ±Ù‚Ø© Ø¹Ù„Ù…ÙŠØ© PDF ÙˆØ§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØµÙ†ÙŠÙ + Ø§Ù„Ù…Ù„Ø®Øµ + Ø§Ø³Ø£Ù„ Ø£Ø³Ø¦Ù„Ø© Ø¹Ù†Ù‡Ø§")

uploaded_file = st.file_uploader("Upload PDF", type=["pdf"])

if uploaded_file is not None:
    text = extract_text_from_pdf(uploaded_file)

    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØµÙ†ÙŠÙ..."):
        classify_prompt = f"ØµÙ†Ù‘Ù Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ±Ù‚Ø© Ø§Ù„Ø¹Ù„Ù…ÙŠØ© Ø­Ø³Ø¨ Ù…Ø¬Ø§Ù„Ù‡Ø§ ÙˆÙ†ÙˆØ¹Ù‡Ø§:\n{text[:1500]}"
        classification = ask_model(classify_prompt, max_new_tokens=200)

    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙ„Ø®ÙŠØµ..."):
        summary_prompt = f"Ù„Ø®Ù‘Øµ Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ±Ù‚Ø© Ø§Ù„Ø¹Ù„Ù…ÙŠØ© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Ù†Ù‚Ø§Ø· ÙˆØ§Ø¶Ø­Ø©:\n{text[:4000]}"
        summary = ask_model(summary_prompt, max_new_tokens=400)

    st.subheader("ğŸ“Œ Ø§Ù„ØªØµÙ†ÙŠÙ")
    st.write(classification)

    st.subheader("ğŸ“ Ø§Ù„Ù…Ù„Ø®Øµ")
    st.write(summary)

    st.subheader("ğŸ“– Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ (Ø¬Ø²Ø¡)")
    st.text(text[:1000])

    # Ù‚Ø³Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
    st.subheader("â“ Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„ÙˆØ±Ù‚Ø©")
    question = st.text_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§")
    if st.button("Ø¥Ø¬Ø§Ø¨Ø©"):
        if question.strip():
            with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©..."):
                qa_prompt = f"Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ù† ÙˆØ±Ù‚Ø© Ø¹Ù„Ù…ÙŠØ©:\n{text[:2000]}\n\nØ§Ù„Ø³Ø¤Ø§Ù„: {question}\nØ§Ù„Ø¥Ø¬Ø§Ø¨Ø©:"
                answer = ask_model(qa_prompt, max_new_tokens=300)
            st.success(answer)
        else:
            st.warning("Ù…Ù† ÙØ¶Ù„Ùƒ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„.")
